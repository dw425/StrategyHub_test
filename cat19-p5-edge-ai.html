<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Edge & On-Device AI | Emerging Technologies | Strategy Hub</title>
    <style>
        :root {
            --brand-orange: #FF9900;
            --page-primary: #10B981;
            --page-light: #34D399;
            --page-glow: rgba(16, 185, 129, 0.15);
            --bg-dark: #0a0a0f;
            --bg-card: #12121a;
            --bg-card-alt: #1a1a2e;
            --bg-hover: #252538;
            --border-color: #2a2a3e;
            --text-primary: #ffffff;
            --text-secondary: #a0a0b0;
            --text-muted: #6a6a7a;
            --green: #10B981;
            --yellow: #F59E0B;
            --red: #EF4444;
            --blue: #3B82F6;
            --cyan: #06B6D4;
            --pink: #EC4899;
            --purple: #8B5CF6;
            --orange: #F97316;
            --sidebar-width: 280px;
            --header-height: 60px;
        }
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; background: var(--bg-dark); color: var(--text-primary); line-height: 1.6; }
        header { background: var(--bg-card); border-bottom: 1px solid var(--border-color); padding: 0 32px; position: fixed; top: 0; left: 0; right: 0; z-index: 1000; height: var(--header-height); display: flex; justify-content: space-between; align-items: center; }
        .logo { font-size: 20px; font-weight: 700; text-decoration: none; color: inherit; }
        .logo span { color: var(--brand-orange); }
        .header-tagline { font-size: 13px; color: var(--text-muted); }
        .sidebar { position: fixed; top: var(--header-height); left: 0; width: var(--sidebar-width); height: calc(100vh - var(--header-height)); background: var(--bg-card); border-right: 1px solid var(--border-color); overflow-y: auto; z-index: 100; padding: 24px 0; }
        .sidebar-section { margin-bottom: 28px; }
        .sidebar-title { font-size: 11px; text-transform: uppercase; letter-spacing: 1.5px; color: var(--page-light); padding: 0 24px; margin-bottom: 12px; font-weight: 600; }
        .sidebar-nav { list-style: none; }
        .sidebar-nav a { display: flex; align-items: center; gap: 10px; padding: 10px 24px; color: var(--text-secondary); text-decoration: none; font-size: 13px; border-left: 3px solid transparent; transition: all 0.2s; }
        .sidebar-nav a:hover { background: var(--bg-hover); color: var(--text-primary); }
        .sidebar-nav a.active { background: var(--page-glow); color: var(--page-light); border-left-color: var(--page-light); }
        .nav-icon { width: 24px; text-align: center; }
        .main-wrapper { margin-left: var(--sidebar-width); margin-top: var(--header-height); }
        .main-content { max-width: 1200px; padding: 32px; }

        /* Hero */
        .hero-compact { display: grid; grid-template-columns: 1fr 1fr; gap: 32px; margin-bottom: 32px; align-items: center; }
        .hero-tag { display: inline-flex; align-items: center; gap: 8px; background: var(--page-glow); border: 1px solid var(--page-primary); padding: 6px 14px; border-radius: 9999px; font-size: 12px; color: var(--page-light); margin-bottom: 16px; }
        .hero-left h1 { font-size: 32px; font-weight: 700; margin-bottom: 12px; }
        .hero-left > p { font-size: 15px; color: var(--text-secondary); line-height: 1.7; }
        .hero-metrics { display: grid; grid-template-columns: repeat(2, 1fr); gap: 12px; }
        .hero-metric { background: var(--bg-card); border: 1px solid var(--border-color); border-radius: 12px; padding: 20px; text-align: center; }
        .hero-metric-value { font-size: 28px; font-weight: 700; color: var(--page-light); }
        .hero-metric-label { font-size: 11px; color: var(--text-muted); margin-top: 4px; }

        /* Modules */
        .module { background: var(--bg-card); border: 1px solid var(--border-color); border-radius: 16px; padding: 28px; margin-bottom: 24px; }
        .module-header { display: flex; align-items: flex-start; gap: 16px; margin-bottom: 24px; }
        .module-icon { width: 48px; height: 48px; background: var(--page-glow); border: 2px solid var(--page-primary); border-radius: 12px; display: flex; align-items: center; justify-content: center; font-size: 22px; flex-shrink: 0; }
        .module-info h2 { font-size: 20px; font-weight: 600; margin-bottom: 4px; }
        .module-info p { font-size: 13px; color: var(--text-secondary); }

        /* Overview Content */
        .overview-content { display: grid; grid-template-columns: 1fr 1fr; gap: 24px; }
        .overview-content h3 { font-size: 15px; font-weight: 600; margin-bottom: 12px; color: var(--page-light); }
        .overview-content p { font-size: 14px; color: var(--text-secondary); line-height: 1.7; margin-bottom: 12px; }
        .overview-content ul { list-style: none; margin-bottom: 12px; }
        .overview-content li { font-size: 14px; color: var(--text-secondary); padding: 4px 0; padding-left: 20px; position: relative; }
        .overview-content li::before { content: '‚Ä¢'; position: absolute; left: 0; color: var(--page-light); }
        .overview-content strong { color: var(--text-primary); }
        .overview-full { grid-column: 1 / -1; }

        /* Comparison Table */
        .comparison-table { width: 100%; border-collapse: collapse; margin-bottom: 24px; }
        .comparison-table th, .comparison-table td { padding: 14px 16px; text-align: left; border-bottom: 1px solid var(--border-color); font-size: 13px; }
        .comparison-table th { background: var(--bg-dark); color: var(--text-primary); font-weight: 600; }
        .comparison-table td { color: var(--text-secondary); }
        .comparison-table tr:hover td { background: var(--bg-hover); }
        .table-highlight { color: var(--page-light) !important; font-weight: 600; }

        /* Stats Row */
        .stats-row { display: grid; grid-template-columns: repeat(4, 1fr); gap: 16px; margin-bottom: 24px; }
        .stat-card { background: var(--bg-dark); border: 1px solid var(--border-color); border-radius: 12px; padding: 20px; text-align: center; }
        .stat-value { font-size: 28px; font-weight: 700; color: var(--page-light); }
        .stat-label { font-size: 12px; color: var(--text-muted); margin-top: 4px; }

        /* Provider Cards */
        .provider-cards { display: grid; grid-template-columns: repeat(3, 1fr); gap: 16px; margin-bottom: 24px; }
        .provider-card { background: var(--bg-dark); border: 2px solid var(--border-color); border-radius: 12px; overflow: hidden; transition: all 0.3s; }
        .provider-card:hover { transform: translateY(-4px); }
        .provider-card.apple { border-color: rgba(168, 85, 247, 0.4); }
        .provider-card.apple:hover { border-color: #A855F7; }
        .provider-card.google { border-color: rgba(16, 185, 129, 0.4); }
        .provider-card.google:hover { border-color: #10B981; }
        .provider-card.microsoft { border-color: rgba(59, 130, 246, 0.4); }
        .provider-card.microsoft:hover { border-color: #3B82F6; }
        .provider-header { padding: 20px; display: flex; align-items: center; gap: 16px; }
        .provider-logo { font-size: 32px; }
        .provider-name { font-size: 16px; font-weight: 700; }
        .provider-sub { font-size: 12px; color: var(--text-muted); }
        .provider-body { padding: 0 20px 20px; }
        .provider-features { list-style: none; }
        .provider-features li { font-size: 13px; color: var(--text-secondary); padding: 8px 0; border-bottom: 1px solid var(--border-color); display: flex; align-items: center; gap: 8px; }
        .provider-features li:last-child { border-bottom: none; }
        .provider-check { color: var(--green); }

        /* Platform Architecture Diagram */
        .platform-arch-grid { display: grid; grid-template-columns: repeat(3, 1fr); gap: 24px; margin-bottom: 32px; }
        .platform-arch { background: var(--bg-dark); border: 2px solid var(--border-color); border-radius: 16px; padding: 24px; position: relative; overflow: hidden; }
        .platform-arch.apple { border-color: rgba(168, 85, 247, 0.4); }
        .platform-arch.google { border-color: rgba(16, 185, 129, 0.4); }
        .platform-arch.microsoft { border-color: rgba(59, 130, 246, 0.4); }
        .platform-arch-header { display: flex; align-items: center; gap: 12px; margin-bottom: 20px; padding-bottom: 16px; border-bottom: 1px solid var(--border-color); }
        .platform-arch-logo { font-size: 36px; }
        .platform-arch-title { font-size: 18px; font-weight: 700; }
        .platform-arch.apple .platform-arch-title { color: #A855F7; }
        .platform-arch.google .platform-arch-title { color: #10B981; }
        .platform-arch.microsoft .platform-arch-title { color: #3B82F6; }
        .platform-arch-sub { font-size: 11px; color: var(--text-muted); }
        
        /* Architecture Flow Diagram */
        .arch-flow { display: flex; flex-direction: column; gap: 12px; margin-bottom: 20px; }
        .arch-flow-row { display: flex; align-items: center; gap: 8px; }
        .arch-flow-node { flex: 1; background: var(--bg-card); border: 1px solid var(--border-color); border-radius: 8px; padding: 10px 12px; text-align: center; font-size: 11px; position: relative; }
        .arch-flow-node.device { border-color: rgba(168, 85, 247, 0.5); }
        .arch-flow-node.model { border-color: rgba(16, 185, 129, 0.5); background: rgba(16, 185, 129, 0.1); }
        .arch-flow-node.cloud { border-color: rgba(59, 130, 246, 0.5); border-style: dashed; }
        .arch-flow-node-icon { font-size: 20px; display: block; margin-bottom: 4px; }
        .arch-flow-node-label { color: var(--text-secondary); font-weight: 500; }
        .arch-flow-arrow { color: var(--text-muted); font-size: 16px; flex-shrink: 0; }
        .arch-flow-arrow.down { transform: rotate(90deg); }
        
        /* Decision diamond */
        .arch-decision { width: 100%; padding: 8px; background: rgba(245, 158, 11, 0.1); border: 1px solid rgba(245, 158, 11, 0.4); border-radius: 8px; text-align: center; font-size: 10px; color: var(--yellow); font-weight: 600; }
        
        /* Platform features with icons */
        .platform-features-visual { display: grid; grid-template-columns: 1fr 1fr; gap: 8px; }
        .platform-feat { display: flex; align-items: center; gap: 8px; padding: 8px 10px; background: var(--bg-card); border-radius: 6px; font-size: 11px; color: var(--text-secondary); }
        .platform-feat-icon { font-size: 14px; }
        
        /* Platform comparison bar */
        .platform-compare { background: var(--bg-dark); border: 1px solid var(--border-color); border-radius: 12px; padding: 24px; }
        .platform-compare-title { font-size: 16px; font-weight: 600; margin-bottom: 20px; text-align: center; }
        .platform-compare-row { display: flex; align-items: center; gap: 16px; margin-bottom: 16px; }
        .platform-compare-row:last-child { margin-bottom: 0; }
        .platform-compare-label { width: 120px; font-size: 13px; color: var(--text-secondary); flex-shrink: 0; }
        .platform-compare-bars { flex: 1; display: flex; gap: 8px; }
        .platform-bar { height: 32px; border-radius: 6px; display: flex; align-items: center; padding: 0 12px; font-size: 11px; font-weight: 600; color: white; }
        .platform-bar.apple { background: linear-gradient(90deg, #A855F7, #8B5CF6); }
        .platform-bar.google { background: linear-gradient(90deg, #10B981, #06B6D4); }
        .platform-bar.microsoft { background: linear-gradient(90deg, #3B82F6, #6366F1); }
        .platform-bar-label { white-space: nowrap; }
        
        /* Device ecosystem visual */
        .device-ecosystem { display: flex; justify-content: center; align-items: center; gap: 32px; padding: 20px; background: var(--bg-dark); border-radius: 12px; margin-bottom: 24px; }
        .device-group { text-align: center; }
        .device-group-icons { display: flex; gap: 8px; margin-bottom: 8px; justify-content: center; }
        .device-icon-box { width: 48px; height: 48px; background: var(--bg-card); border: 1px solid var(--border-color); border-radius: 10px; display: flex; align-items: center; justify-content: center; font-size: 24px; }
        .device-group.apple .device-icon-box { border-color: rgba(168, 85, 247, 0.4); }
        .device-group.google .device-icon-box { border-color: rgba(16, 185, 129, 0.4); }
        .device-group.microsoft .device-icon-box { border-color: rgba(59, 130, 246, 0.4); }
        .device-group-label { font-size: 12px; font-weight: 600; }
        .device-group.apple .device-group-label { color: #A855F7; }
        .device-group.google .device-group-label { color: #10B981; }
        .device-group.microsoft .device-group-label { color: #3B82F6; }
        .device-group-sub { font-size: 10px; color: var(--text-muted); }

        /* Deep Dive */
        .deep-dive { background: var(--bg-dark); border: 1px solid var(--border-color); border-radius: 12px; margin-bottom: 24px; overflow: hidden; }
        .deep-header { padding: 20px 24px; border-bottom: 1px solid var(--border-color); display: flex; align-items: center; gap: 16px; }
        .deep-icon { font-size: 28px; }
        .deep-title { font-size: 18px; font-weight: 600; }
        .deep-subtitle { font-size: 12px; color: var(--text-muted); }
        .deep-body { padding: 24px; }
        .deep-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 24px; }
        .deep-section h4 { font-size: 14px; font-weight: 600; margin-bottom: 12px; color: var(--page-light); }
        .deep-section ul { list-style: none; }
        .deep-section li { font-size: 13px; color: var(--text-secondary); padding: 6px 0; padding-left: 20px; position: relative; }
        .deep-section li::before { content: '‚Üí'; position: absolute; left: 0; color: var(--page-light); }

        /* SW Grid (Strengths/Weaknesses) */
        .sw-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 16px; margin-bottom: 24px; }
        .sw-card { background: var(--bg-dark); border: 1px solid var(--border-color); border-radius: 12px; padding: 20px; }
        .sw-title { font-size: 14px; font-weight: 600; margin-bottom: 12px; display: flex; align-items: center; gap: 8px; }
        .sw-title.green { color: var(--green); }
        .sw-title.yellow { color: var(--yellow); }
        .sw-list { list-style: none; }
        .sw-list li { font-size: 13px; color: var(--text-secondary); padding: 6px 0; padding-left: 16px; position: relative; }
        .sw-card.strengths .sw-list li::before { content: '‚úì'; position: absolute; left: 0; color: var(--green); }
        .sw-card.weaknesses .sw-list li::before { content: '‚ö†'; position: absolute; left: 0; color: var(--yellow); font-size: 11px; }

        /* Model Cards */
        .model-grid { display: grid; grid-template-columns: repeat(3, 1fr); gap: 16px; margin-bottom: 24px; }
        .model-card { background: var(--bg-dark); border: 1px solid var(--border-color); border-radius: 12px; padding: 20px; transition: all 0.3s; }
        .model-card:hover { border-color: var(--page-primary); }
        .model-header { display: flex; justify-content: space-between; align-items: flex-start; margin-bottom: 12px; }
        .model-name { font-size: 15px; font-weight: 600; }
        .model-company { font-size: 11px; color: var(--text-muted); }
        .model-badge { padding: 4px 10px; background: var(--page-glow); border: 1px solid var(--page-primary); border-radius: 9999px; font-size: 11px; color: var(--page-light); font-weight: 600; }
        .model-desc { font-size: 12px; color: var(--text-secondary); margin-bottom: 12px; line-height: 1.5; }
        .model-specs { display: flex; gap: 16px; font-size: 11px; }
        .model-spec-value { color: var(--text-primary); font-weight: 600; }
        .model-spec-label { color: var(--text-muted); }

        /* Use Cases */
        .usecase-grid { display: grid; grid-template-columns: repeat(2, 1fr); gap: 16px; margin-bottom: 24px; }
        .usecase-card { background: var(--bg-dark); border: 1px solid var(--border-color); border-radius: 12px; padding: 20px; display: flex; gap: 16px; transition: all 0.3s; }
        .usecase-card:hover { border-color: var(--page-primary); }
        .usecase-icon { width: 48px; height: 48px; background: var(--page-glow); border: 1px solid var(--page-primary); border-radius: 12px; display: flex; align-items: center; justify-content: center; font-size: 24px; flex-shrink: 0; }
        .usecase-title { font-size: 15px; font-weight: 600; margin-bottom: 6px; }
        .usecase-desc { font-size: 13px; color: var(--text-secondary); line-height: 1.5; margin-bottom: 8px; }
        .usecase-examples { font-size: 11px; color: var(--text-muted); }

        /* Best Practices */
        .practices-grid { display: grid; grid-template-columns: repeat(2, 1fr); gap: 16px; margin-bottom: 24px; }
        .practice-card { display: flex; gap: 16px; padding: 20px; background: var(--bg-dark); border: 1px solid var(--border-color); border-radius: 12px; }
        .practice-num { width: 32px; height: 32px; background: var(--page-glow); border: 1px solid var(--page-primary); border-radius: 50%; display: flex; align-items: center; justify-content: center; font-size: 14px; font-weight: 700; color: var(--page-light); flex-shrink: 0; }
        .practice-title { font-size: 14px; font-weight: 600; margin-bottom: 4px; }
        .practice-desc { font-size: 12px; color: var(--text-secondary); line-height: 1.5; }

        /* Timeline */
        .timeline-container { background: var(--bg-dark); border: 1px solid var(--border-color); border-radius: 12px; padding: 24px; margin-bottom: 24px; }
        .timeline-row { display: flex; gap: 16px; margin-bottom: 16px; }
        .timeline-row:last-child { margin-bottom: 0; }
        .timeline-year { width: 80px; font-size: 16px; font-weight: 700; color: var(--page-light); flex-shrink: 0; }
        .timeline-content { flex: 1; font-size: 14px; color: var(--text-secondary); padding-left: 16px; border-left: 2px solid var(--page-primary); }
        .timeline-content strong { color: var(--text-primary); }

        /* Agent Grid */
        .agent-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 24px; }
        .agent-info h3 { font-size: 18px; font-weight: 600; margin-bottom: 12px; color: var(--page-light); }
        .agent-info > p { font-size: 14px; color: var(--text-secondary); line-height: 1.7; margin-bottom: 20px; }
        .agent-capabilities { display: flex; flex-direction: column; gap: 10px; }
        .agent-capability { display: flex; align-items: center; gap: 12px; padding: 12px 16px; background: var(--bg-dark); border: 1px solid var(--border-color); border-radius: 8px; font-size: 13px; color: var(--text-secondary); }
        .capability-icon { font-size: 18px; }
        .agent-code { background: var(--bg-dark); border: 1px solid var(--border-color); border-radius: 12px; overflow: hidden; }
        .code-header { background: var(--bg-card-alt); padding: 12px 16px; font-size: 12px; font-weight: 600; border-bottom: 1px solid var(--border-color); font-family: monospace; color: var(--text-muted); }
        .code-content { padding: 20px; font-family: 'Monaco', 'Menlo', monospace; font-size: 12px; line-height: 1.6; overflow-x: auto; color: var(--text-secondary); }
        .ck { color: #FF7B72; }
        .cs { color: #A5D6FF; }
        .cf { color: #79C0FF; }

        /* Related */
        .related-grid { display: grid; grid-template-columns: repeat(3, 1fr); gap: 16px; }
        .related-card { background: var(--bg-card); border: 1px solid var(--border-color); border-radius: 12px; padding: 20px; text-decoration: none; color: inherit; transition: all 0.2s; }
        .related-card:hover { border-color: var(--page-primary); transform: translateY(-2px); }
        .related-icon { font-size: 24px; margin-bottom: 12px; }
        .related-title { font-size: 14px; font-weight: 600; margin-bottom: 6px; }
        .related-desc { font-size: 12px; color: var(--text-secondary); }

        footer { background: var(--bg-card); border-top: 1px solid var(--border-color); padding: 24px 32px; margin-left: var(--sidebar-width); }
        .footer-nav { display: flex; justify-content: space-between; align-items: center; }
        .footer-link { display: flex; align-items: center; gap: 12px; text-decoration: none; color: var(--text-secondary); padding: 12px 20px; background: var(--bg-card-alt); border: 1px solid var(--border-color); border-radius: 12px; transition: all 0.2s; }
        .footer-link:hover { border-color: var(--page-primary); color: var(--text-primary); }
        .footer-link-label { font-size: 11px; color: var(--text-muted); }
        .footer-link-title { font-size: 13px; font-weight: 600; }
        .footer-brand { font-size: 13px; color: var(--text-muted); }
        .footer-brand span { color: var(--brand-orange); }

        @media (max-width: 1024px) {
            .sidebar { display: none; }
            .main-wrapper { margin-left: 0; }
            footer { margin-left: 0; }
            .hero-compact, .overview-content, .sw-grid, .deep-grid, .agent-grid { grid-template-columns: 1fr; }
            .provider-cards, .model-grid, .usecase-grid, .practices-grid, .related-grid { grid-template-columns: 1fr; }
            .platform-arch-grid { grid-template-columns: 1fr; }
            .device-ecosystem { flex-direction: column; gap: 20px; }
            .platform-compare-row { flex-direction: column; gap: 8px; }
            .platform-compare-label { width: 100%; }
            .platform-compare-bars { flex-direction: column; }
            .stats-row { grid-template-columns: repeat(2, 1fr); }
        }
    </style>
</head>
<body>

<header>
    <a href="index.html" class="logo"><span>STRATEGY</span>HUB</a>
    <div class="header-tagline">Enterprise Technology Knowledge Base</div>
</header>

<aside class="sidebar">
    <div class="sidebar-section">
        <div class="sidebar-title">üöÄ Category 19</div>
        <ul class="sidebar-nav">
            <li><a href="cat19-emerging-technologies-overview.html"><span class="nav-icon">üè†</span> Overview</a></li>
            <li><a href="cat19-p1-foundation-models.html"><span class="nav-icon">üß†</span> 19.1 Foundation Models</a></li>
            <li><a href="cat19-p2-agentic-ai.html"><span class="nav-icon">ü§ñ</span> 19.2 Agentic AI</a></li>
            <li><a href="cat19-p3-multimodal-ai.html"><span class="nav-icon">üé®</span> 19.3 Multimodal AI</a></li>
            <li><a href="cat19-p4-ai-coding.html"><span class="nav-icon">üíª</span> 19.4 AI Coding Tools</a></li>
            <li><a href="cat19-p5-edge-ai.html" class="active"><span class="nav-icon">üì±</span> 19.5 Edge & On-Device</a></li>
            <li><a href="cat19-p6-ai-infrastructure.html"><span class="nav-icon">üñ•Ô∏è</span> 19.6 AI Infrastructure</a></li>
            <li><a href="cat19-p7-ai-safety.html"><span class="nav-icon">üõ°Ô∏è</span> 19.7 AI Safety & Governance</a></li>
            <li><a href="cat19-p8-rag-knowledge.html"><span class="nav-icon">üìö</span> 19.8 RAG & Knowledge</a></li>
            <li><a href="cat19-p9-observability.html"><span class="nav-icon">üìä</span> 19.9 Observability & Evals</a></li>
            <li><a href="cat19-p10-enterprise-adoption.html"><span class="nav-icon">üè¢</span> 19.10 Enterprise Adoption</a></li>
        </ul>
    </div>
    <div class="sidebar-section">
        <div class="sidebar-title">üìë On This Page</div>
        <ul class="sidebar-nav">
            <li><a href="#overview"><span class="nav-icon">üí°</span> Overview</a></li>
            <li><a href="#hardware"><span class="nav-icon">üîß</span> NPU Hardware</a></li>
            <li><a href="#platforms"><span class="nav-icon">üñ•Ô∏è</span> Platform AI</a></li>
            <li><a href="#models"><span class="nav-icon">üß†</span> Edge Models</a></li>
            <li><a href="#quantization"><span class="nav-icon">üìâ</span> Quantization</a></li>
            <li><a href="#runtimes"><span class="nav-icon">‚öôÔ∏è</span> Runtimes</a></li>
            <li><a href="#privacy"><span class="nav-icon">üîê</span> Privacy</a></li>
            <li><a href="#usecases"><span class="nav-icon">üíº</span> Use Cases</a></li>
            <li><a href="#practices"><span class="nav-icon">‚úÖ</span> Best Practices</a></li>
            <li><a href="#future"><span class="nav-icon">üîÆ</span> Future</a></li>
            <li><a href="#agent"><span class="nav-icon">ü§ñ</span> Agent This</a></li>
        </ul>
    </div>
</aside>

<div class="main-wrapper">
    <div class="main-content">

        <!-- Hero -->
        <section class="hero-compact">
            <div class="hero-left">
                <span class="hero-tag">üì± Page 19.5</span>
                <h1>Edge & On-Device AI</h1>
                <p>AI that runs locally on phones, laptops, and edge devices rather than in cloud data centers. Enables real-time inference, privacy-preserving computation, and offline functionality‚Äîcapabilities cloud AI cannot provide.</p>
            </div>
            <div class="hero-metrics">
                <div class="hero-metric"><div class="hero-metric-value">~10ms</div><div class="hero-metric-label">Local Inference Latency</div></div>
                <div class="hero-metric"><div class="hero-metric-value">100%</div><div class="hero-metric-label">Data Privacy (No Transmission)</div></div>
                <div class="hero-metric"><div class="hero-metric-value">3B+</div><div class="hero-metric-label">Devices with NPUs (2024)</div></div>
                <div class="hero-metric"><div class="hero-metric-value">50%</div><div class="hero-metric-label">AI Workloads Moving to Edge</div></div>
            </div>
        </section>

        <!-- Overview -->
        <section class="module" id="overview">
            <div class="module-header">
                <div class="module-icon">üí°</div>
                <div class="module-info">
                    <h2>Overview</h2>
                    <p>Understanding edge and on-device AI</p>
                </div>
            </div>

            <div class="overview-content">
                <div>
                    <h3>What is Edge AI?</h3>
                    <p><strong>Edge AI</strong> refers to running machine learning models directly on end-user devices‚Äîsmartphones, laptops, IoT devices, vehicles‚Äîrather than sending data to cloud servers for processing. Computation happens where data is generated, eliminating network round-trips.</p>
                    <p>This paradigm shift enables applications that were previously impossible: real-time video processing at 60fps, privacy-preserving health monitoring, offline voice assistants, and instant language translation without internet connectivity.</p>
                </div>
                <div>
                    <h3>Why Edge AI Now?</h3>
                    <p>Three converging trends are driving edge AI adoption:</p>
                    <ul>
                        <li><strong>Hardware:</strong> NPUs in consumer devices now deliver 30-50 TOPS (trillion operations per second)</li>
                        <li><strong>Models:</strong> Small language models (1-7B parameters) approach GPT-3 quality for many tasks</li>
                        <li><strong>Optimization:</strong> Quantization reduces model size 4-8x with minimal quality loss</li>
                    </ul>
                    <p>Every major platform‚ÄîApple, Google, Microsoft, Meta‚Äînow ships devices with dedicated AI acceleration hardware.</p>
                </div>
            </div>

            <div class="sw-grid">
                <div class="sw-card strengths">
                    <div class="sw-title green">‚úì Edge AI Advantages</div>
                    <ul class="sw-list">
                        <li>Zero latency for user interactions (~10ms vs ~500ms cloud)</li>
                        <li>Complete privacy‚Äîdata never leaves the device</li>
                        <li>Works offline without internet connectivity</li>
                        <li>No per-inference API costs at scale</li>
                        <li>Regulatory compliance simplified (GDPR, HIPAA)</li>
                        <li>Always available‚Äîno cloud outage dependency</li>
                    </ul>
                </div>
                <div class="sw-card weaknesses">
                    <div class="sw-title yellow">‚ö† Considerations</div>
                    <ul class="sw-list">
                        <li>Limited model size (1-13B vs 400B+ cloud models)</li>
                        <li>Less reasoning capability than frontier models</li>
                        <li>No access to real-time information (web search)</li>
                        <li>Battery and thermal constraints on mobile</li>
                        <li>Model updates require app updates</li>
                        <li>Hardware fragmentation across devices</li>
                    </ul>
                </div>
            </div>
        </section>

        <!-- NPU Hardware -->
        <section class="module" id="hardware">
            <div class="module-header">
                <div class="module-icon">üîß</div>
                <div class="module-info">
                    <h2>NPU Hardware</h2>
                    <p>The silicon powering edge AI</p>
                </div>
            </div>

            <div class="overview-content" style="margin-bottom: 24px;">
                <div class="overview-full">
                    <h3>What are NPUs?</h3>
                    <p><strong>Neural Processing Units (NPUs)</strong> are specialized chips optimized for neural network operations. Unlike GPUs (general parallel computing) or CPUs (general sequential computing), NPUs are designed specifically for matrix multiplication and activation functions that dominate AI workloads. They deliver <strong>10-100x better performance per watt</strong> than running AI on CPUs, making sustained on-device inference practical.</p>
                </div>
            </div>

            <table class="comparison-table">
                <thead>
                    <tr>
                        <th>Vendor</th>
                        <th>Chip</th>
                        <th>NPU Performance</th>
                        <th>Target Device</th>
                        <th>Notable Features</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>NVIDIA</strong></td>
                        <td>Jetson Thor</td>
                        <td class="table-highlight">800 TOPS</td>
                        <td>Edge Server / Robotics</td>
                        <td>Transformer engine, 100GB memory</td>
                    </tr>
                    <tr>
                        <td><strong>AMD</strong></td>
                        <td>Strix Point (Ryzen AI)</td>
                        <td class="table-highlight">50 TOPS</td>
                        <td>Laptop</td>
                        <td>XDNA 2 architecture, Copilot+ ready</td>
                    </tr>
                    <tr>
                        <td><strong>Intel</strong></td>
                        <td>Lunar Lake</td>
                        <td class="table-highlight">48 TOPS</td>
                        <td>Laptop</td>
                        <td>NPU 4, low power design</td>
                    </tr>
                    <tr>
                        <td><strong>Qualcomm</strong></td>
                        <td>Snapdragon X Elite</td>
                        <td class="table-highlight">45 TOPS</td>
                        <td>Laptop / Tablet</td>
                        <td>Hexagon NPU, Windows on ARM</td>
                    </tr>
                    <tr>
                        <td><strong>Apple</strong></td>
                        <td>M3 Pro/Max</td>
                        <td class="table-highlight">38 TOPS</td>
                        <td>Mac</td>
                        <td>Neural Engine, unified memory</td>
                    </tr>
                    <tr>
                        <td><strong>Apple</strong></td>
                        <td>A17 Pro</td>
                        <td class="table-highlight">35 TOPS</td>
                        <td>iPhone 15 Pro</td>
                        <td>Apple Intelligence capable</td>
                    </tr>
                    <tr>
                        <td><strong>Google</strong></td>
                        <td>Tensor G4</td>
                        <td class="table-highlight">~30 TOPS</td>
                        <td>Pixel 9</td>
                        <td>Custom for Gemini Nano</td>
                    </tr>
                    <tr>
                        <td><strong>Qualcomm</strong></td>
                        <td>Snapdragon 8 Gen 3</td>
                        <td class="table-highlight">~25 TOPS</td>
                        <td>Android Flagship</td>
                        <td>Hexagon, multimodal AI</td>
                    </tr>
                </tbody>
            </table>

            <div class="overview-content">
                <div>
                    <h3>TOPS Explained</h3>
                    <p><strong>TOPS (Trillion Operations Per Second)</strong> measures theoretical peak throughput for INT8 operations. Real-world performance depends on model architecture, memory bandwidth, and software optimization. A 7B parameter model at Q4 quantization typically needs 15-20 TOPS for comfortable real-time inference.</p>
                </div>
                <div>
                    <h3>Memory Matters More</h3>
                    <p>NPU performance is often <strong>memory-bandwidth limited</strong>, not compute-limited. Apple's unified memory architecture excels here‚Äîan M3 Max with 128GB unified memory can run 70B models that won't fit on discrete NPUs with 16GB. When evaluating hardware, check both TOPS and memory bandwidth.</p>
                </div>
            </div>
        </section>

        <!-- Platform AI -->
        <section class="module" id="platforms">
            <div class="module-header">
                <div class="module-icon">üñ•Ô∏è</div>
                <div class="module-info">
                    <h2>Platform AI</h2>
                    <p>How Apple, Google, and Microsoft deploy edge AI</p>
                </div>
            </div>

            <!-- Device Ecosystem Visual -->
            <div class="device-ecosystem">
                <div class="device-group apple">
                    <div class="device-group-icons">
                        <div class="device-icon-box">üì±</div>
                        <div class="device-icon-box">üíª</div>
                        <div class="device-icon-box">‚åö</div>
                    </div>
                    <div class="device-group-label">Apple</div>
                    <div class="device-group-sub">iPhone 15 Pro+ ‚Ä¢ M1+ Mac</div>
                </div>
                <div class="device-group google">
                    <div class="device-group-icons">
                        <div class="device-icon-box">üì±</div>
                        <div class="device-icon-box">üì≤</div>
                        <div class="device-icon-box">‚åö</div>
                    </div>
                    <div class="device-group-label">Android</div>
                    <div class="device-group-sub">Pixel 8+ ‚Ä¢ Galaxy S24+</div>
                </div>
                <div class="device-group microsoft">
                    <div class="device-group-icons">
                        <div class="device-icon-box">üíª</div>
                        <div class="device-icon-box">üñ•Ô∏è</div>
                        <div class="device-icon-box">üì≤</div>
                    </div>
                    <div class="device-group-label">Windows</div>
                    <div class="device-group-sub">Copilot+ PCs ‚Ä¢ 40+ TOPS</div>
                </div>
            </div>

            <!-- Architecture Flow Diagrams -->
            <div class="platform-arch-grid">
                <!-- Apple Architecture -->
                <div class="platform-arch apple">
                    <div class="platform-arch-header">
                        <div class="platform-arch-logo">üçé</div>
                        <div>
                            <div class="platform-arch-title">Apple Intelligence</div>
                            <div class="platform-arch-sub">Privacy-first hybrid approach</div>
                        </div>
                    </div>
                    
                    <div class="arch-flow">
                        <div class="arch-flow-row">
                            <div class="arch-flow-node device">
                                <span class="arch-flow-node-icon">üì±</span>
                                <span class="arch-flow-node-label">User Request</span>
                            </div>
                        </div>
                        <div class="arch-flow-arrow down" style="text-align: center;">‚Üì</div>
                        <div class="arch-decision">Simple task? ‚Üí On-Device</div>
                        <div class="arch-flow-arrow down" style="text-align: center;">‚Üì</div>
                        <div class="arch-flow-row">
                            <div class="arch-flow-node model">
                                <span class="arch-flow-node-icon">üß†</span>
                                <span class="arch-flow-node-label">On-Device LLM</span>
                            </div>
                            <span class="arch-flow-arrow">‚Üí</span>
                            <div class="arch-flow-node cloud">
                                <span class="arch-flow-node-icon">‚òÅÔ∏è</span>
                                <span class="arch-flow-node-label">Private Cloud</span>
                            </div>
                        </div>
                    </div>
                    
                    <div class="platform-features-visual">
                        <div class="platform-feat"><span class="platform-feat-icon">‚úçÔ∏è</span> Writing Tools</div>
                        <div class="platform-feat"><span class="platform-feat-icon">üîî</span> Summaries</div>
                        <div class="platform-feat"><span class="platform-feat-icon">üé®</span> Image Gen</div>
                        <div class="platform-feat"><span class="platform-feat-icon">üòÄ</span> Genmoji</div>
                        <div class="platform-feat"><span class="platform-feat-icon">üéôÔ∏è</span> Smart Siri</div>
                        <div class="platform-feat"><span class="platform-feat-icon">üîê</span> Private Cloud</div>
                    </div>
                </div>

                <!-- Google Architecture -->
                <div class="platform-arch google">
                    <div class="platform-arch-header">
                        <div class="platform-arch-logo">ü§ñ</div>
                        <div>
                            <div class="platform-arch-title">Android AI</div>
                            <div class="platform-arch-sub">Gemini Nano on-device</div>
                        </div>
                    </div>
                    
                    <div class="arch-flow">
                        <div class="arch-flow-row">
                            <div class="arch-flow-node device">
                                <span class="arch-flow-node-icon">üì±</span>
                                <span class="arch-flow-node-label">User Request</span>
                            </div>
                        </div>
                        <div class="arch-flow-arrow down" style="text-align: center;">‚Üì</div>
                        <div class="arch-decision">AICore API Check</div>
                        <div class="arch-flow-arrow down" style="text-align: center;">‚Üì</div>
                        <div class="arch-flow-row">
                            <div class="arch-flow-node model">
                                <span class="arch-flow-node-icon">‚ú®</span>
                                <span class="arch-flow-node-label">Gemini Nano</span>
                            </div>
                            <span class="arch-flow-arrow">‚Üí</span>
                            <div class="arch-flow-node cloud">
                                <span class="arch-flow-node-icon">üåê</span>
                                <span class="arch-flow-node-label">Gemini Pro</span>
                            </div>
                        </div>
                    </div>
                    
                    <div class="platform-features-visual">
                        <div class="platform-feat"><span class="platform-feat-icon">üé§</span> Recorder</div>
                        <div class="platform-feat"><span class="platform-feat-icon">üí¨</span> Smart Reply</div>
                        <div class="platform-feat"><span class="platform-feat-icon">‚≠ï</span> Circle Search</div>
                        <div class="platform-feat"><span class="platform-feat-icon">üåç</span> Live Translate</div>
                        <div class="platform-feat"><span class="platform-feat-icon">üìû</span> Call Screen</div>
                        <div class="platform-feat"><span class="platform-feat-icon">üìù</span> Summarize</div>
                    </div>
                </div>

                <!-- Microsoft Architecture -->
                <div class="platform-arch microsoft">
                    <div class="platform-arch-header">
                        <div class="platform-arch-logo">ü™ü</div>
                        <div>
                            <div class="platform-arch-title">Copilot+ PCs</div>
                            <div class="platform-arch-sub">NPU-first hardware spec</div>
                        </div>
                    </div>
                    
                    <div class="arch-flow">
                        <div class="arch-flow-row">
                            <div class="arch-flow-node device">
                                <span class="arch-flow-node-icon">üíª</span>
                                <span class="arch-flow-node-label">User Request</span>
                            </div>
                        </div>
                        <div class="arch-flow-arrow down" style="text-align: center;">‚Üì</div>
                        <div class="arch-decision">40+ TOPS NPU Available</div>
                        <div class="arch-flow-arrow down" style="text-align: center;">‚Üì</div>
                        <div class="arch-flow-row">
                            <div class="arch-flow-node model">
                                <span class="arch-flow-node-icon">üî∑</span>
                                <span class="arch-flow-node-label">Phi Silica</span>
                            </div>
                            <span class="arch-flow-arrow">‚Üí</span>
                            <div class="arch-flow-node cloud">
                                <span class="arch-flow-node-icon">ü§ñ</span>
                                <span class="arch-flow-node-label">Copilot Cloud</span>
                            </div>
                        </div>
                    </div>
                    
                    <div class="platform-features-visual">
                        <div class="platform-feat"><span class="platform-feat-icon">üîç</span> Recall</div>
                        <div class="platform-feat"><span class="platform-feat-icon">üé®</span> Cocreator</div>
                        <div class="platform-feat"><span class="platform-feat-icon">üé•</span> Studio FX</div>
                        <div class="platform-feat"><span class="platform-feat-icon">üí¨</span> Captions</div>
                        <div class="platform-feat"><span class="platform-feat-icon">‚öôÔ∏è</span> ONNX RT</div>
                        <div class="platform-feat"><span class="platform-feat-icon">üî∑</span> DirectML</div>
                    </div>
                </div>
            </div>

            <!-- Capability Comparison -->
            <div class="platform-compare">
                <div class="platform-compare-title">Platform Capability Comparison</div>
                
                <div class="platform-compare-row">
                    <div class="platform-compare-label">On-Device LLM</div>
                    <div class="platform-compare-bars">
                        <div class="platform-bar apple" style="flex: 3;"><span class="platform-bar-label">~3B params</span></div>
                        <div class="platform-bar google" style="flex: 2;"><span class="platform-bar-label">~1.8B</span></div>
                        <div class="platform-bar microsoft" style="flex: 3;"><span class="platform-bar-label">Phi ~3.8B</span></div>
                    </div>
                </div>
                
                <div class="platform-compare-row">
                    <div class="platform-compare-label">Image Generation</div>
                    <div class="platform-compare-bars">
                        <div class="platform-bar apple" style="flex: 4;"><span class="platform-bar-label">Image Playground</span></div>
                        <div class="platform-bar google" style="flex: 1;"><span class="platform-bar-label">‚Äî</span></div>
                        <div class="platform-bar microsoft" style="flex: 3;"><span class="platform-bar-label">Cocreator</span></div>
                    </div>
                </div>
                
                <div class="platform-compare-row">
                    <div class="platform-compare-label">Developer API</div>
                    <div class="platform-compare-bars">
                        <div class="platform-bar apple" style="flex: 2;"><span class="platform-bar-label">Core ML</span></div>
                        <div class="platform-bar google" style="flex: 3;"><span class="platform-bar-label">AICore API</span></div>
                        <div class="platform-bar microsoft" style="flex: 4;"><span class="platform-bar-label">ONNX / DirectML</span></div>
                    </div>
                </div>
                
                <div class="platform-compare-row">
                    <div class="platform-compare-label">Privacy Focus</div>
                    <div class="platform-compare-bars">
                        <div class="platform-bar apple" style="flex: 5;"><span class="platform-bar-label">Private Cloud Compute</span></div>
                        <div class="platform-bar google" style="flex: 3;"><span class="platform-bar-label">On-device first</span></div>
                        <div class="platform-bar microsoft" style="flex: 3;"><span class="platform-bar-label">Local + Cloud</span></div>
                    </div>
                </div>
            </div>

            <div class="overview-content">
                <div class="overview-full">
                    <h3>Platform Strategy Analysis</h3>
                    <p><strong>Apple</strong> leads with privacy‚Äîtheir hybrid architecture routes simple tasks to on-device models while complex requests go to Private Cloud Compute, which runs on Apple Silicon in secure enclaves that Apple itself cannot access. <strong>Google</strong> focuses on Gemini Nano as a universal on-device foundation available to all Android developers via the AICore API, making edge AI accessible across the ecosystem. <strong>Microsoft</strong> takes a hardware-first approach, defining Copilot+ PCs as a 40+ TOPS NPU specification that creates a standardized target for developers across multiple OEMs. All three are racing to make edge AI a platform differentiator‚Äîthe winner will own the next era of personal computing.</p>
                </div>
            </div>
        </section>

        <!-- Edge Models -->
        <section class="module" id="models">
            <div class="module-header">
                <div class="module-icon">üß†</div>
                <div class="module-info">
                    <h2>Edge-Optimized Models</h2>
                    <p>Small models designed for local deployment</p>
                </div>
            </div>

            <div class="model-grid">
                <div class="model-card">
                    <div class="model-header">
                        <div><div class="model-name">Llama 3.2 1B/3B</div><div class="model-company">Meta</div></div>
                        <span class="model-badge">1-3B</span>
                    </div>
                    <p class="model-desc">Meta's smallest Llama models, optimized for mobile deployment. Multilingual support, instruction-tuned. Open weights under Llama license.</p>
                    <div class="model-specs">
                        <div><span class="model-spec-value">128K</span> <span class="model-spec-label">context</span></div>
                        <div><span class="model-spec-value">~2GB</span> <span class="model-spec-label">Q4 size</span></div>
                    </div>
                </div>

                <div class="model-card">
                    <div class="model-header">
                        <div><div class="model-name">Phi-3 Mini</div><div class="model-company">Microsoft</div></div>
                        <span class="model-badge">3.8B</span>
                    </div>
                    <p class="model-desc">Exceptional reasoning for size. Trained on high-quality data. Optimized for ONNX Runtime and Windows. MIT license.</p>
                    <div class="model-specs">
                        <div><span class="model-spec-value">128K</span> <span class="model-spec-label">context</span></div>
                        <div><span class="model-spec-value">~2.5GB</span> <span class="model-spec-label">Q4 size</span></div>
                    </div>
                </div>

                <div class="model-card">
                    <div class="model-header">
                        <div><div class="model-name">Gemma 2 2B</div><div class="model-company">Google</div></div>
                        <span class="model-badge">2B</span>
                    </div>
                    <p class="model-desc">Derived from Gemini architecture. Excellent for classification and simple generation. Apache 2.0 license.</p>
                    <div class="model-specs">
                        <div><span class="model-spec-value">8K</span> <span class="model-spec-label">context</span></div>
                        <div><span class="model-spec-value">~1.5GB</span> <span class="model-spec-label">Q4 size</span></div>
                    </div>
                </div>

                <div class="model-card">
                    <div class="model-header">
                        <div><div class="model-name">Mistral 7B</div><div class="model-company">Mistral AI</div></div>
                        <span class="model-badge">7B</span>
                    </div>
                    <p class="model-desc">Best quality-to-size ratio in open source. Strong instruction following. Fits on laptops with Q4. Apache 2.0 license.</p>
                    <div class="model-specs">
                        <div><span class="model-spec-value">32K</span> <span class="model-spec-label">context</span></div>
                        <div><span class="model-spec-value">~4GB</span> <span class="model-spec-label">Q4 size</span></div>
                    </div>
                </div>

                <div class="model-card">
                    <div class="model-header">
                        <div><div class="model-name">Qwen2.5</div><div class="model-company">Alibaba</div></div>
                        <span class="model-badge">0.5-7B</span>
                    </div>
                    <p class="model-desc">Full size range from 0.5B to 72B. Excellent multilingual and Asian language support. Apache 2.0 license.</p>
                    <div class="model-specs">
                        <div><span class="model-spec-value">128K</span> <span class="model-spec-label">context</span></div>
                        <div><span class="model-spec-value">Varies</span> <span class="model-spec-label">size</span></div>
                    </div>
                </div>

                <div class="model-card">
                    <div class="model-header">
                        <div><div class="model-name">Gemini Nano</div><div class="model-company">Google</div></div>
                        <span class="model-badge">~1.8B</span>
                    </div>
                    <p class="model-desc">Powers Android AI features. Optimized for Tensor and Snapdragon. Available via AICore API on Android 14+. Closed source.</p>
                    <div class="model-specs">
                        <div><span class="model-spec-value">32K</span> <span class="model-spec-label">context</span></div>
                        <div><span class="model-spec-value">Closed</span> <span class="model-spec-label">source</span></div>
                    </div>
                </div>
            </div>

            <div class="overview-content">
                <div>
                    <h3>Model Selection by Device</h3>
                    <ul>
                        <li><strong>Phones (4-8GB RAM):</strong> Gemini Nano, Llama 3.2 1B, Phi-3 Mini (Q4)</li>
                        <li><strong>Tablets (8-16GB RAM):</strong> Llama 3.2 3B, Gemma 2B, Mistral 7B (Q4)</li>
                        <li><strong>Laptops (16-64GB RAM):</strong> Mistral 7B, Llama 3.1 8B, Phi-3 Medium</li>
                        <li><strong>Edge Servers (64GB+ RAM):</strong> Llama 3.1 70B, Mixtral 8x7B</li>
                    </ul>
                </div>
                <div>
                    <h3>Open vs Closed Trade-offs</h3>
                    <p><strong>Open models</strong> (Llama, Mistral, Phi) offer full control‚Äîyou can fine-tune, quantize, and deploy anywhere. <strong>Closed models</strong> (Gemini Nano, Apple's models) are platform-optimized but locked to specific devices. For production apps, open models provide more flexibility; for consumer features, platform APIs offer the smoothest experience.</p>
                </div>
            </div>
        </section>

        <!-- Quantization -->
        <section class="module" id="quantization">
            <div class="module-header">
                <div class="module-icon">üìâ</div>
                <div class="module-info">
                    <h2>Quantization</h2>
                    <p>Making models fit on devices</p>
                </div>
            </div>

            <div class="overview-content" style="margin-bottom: 24px;">
                <div class="overview-full">
                    <h3>What is Quantization?</h3>
                    <p><strong>Quantization</strong> reduces model precision from 32-bit or 16-bit floating point to lower bit representations (8-bit, 4-bit, or even 2-bit). This shrinks model size proportionally‚Äîa 7B model at FP16 (14GB) becomes ~4GB at 4-bit quantization‚Äîwhile maintaining most of the model's capability. Modern quantization techniques like GPTQ, AWQ, and GGML's k-quant methods have made 4-bit quantization practical with minimal quality loss.</p>
                </div>
            </div>

            <table class="comparison-table">
                <thead>
                    <tr>
                        <th>Precision</th>
                        <th>Bits</th>
                        <th>Size (7B Model)</th>
                        <th>Quality Retention</th>
                        <th>Use Case</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>FP32</strong> (Full)</td>
                        <td>32-bit</td>
                        <td>~28GB</td>
                        <td>100% (baseline)</td>
                        <td>Training, research</td>
                    </tr>
                    <tr>
                        <td><strong>FP16</strong> (Half)</td>
                        <td>16-bit</td>
                        <td>~14GB</td>
                        <td>~99%</td>
                        <td>GPU inference, fine-tuning</td>
                    </tr>
                    <tr>
                        <td><strong>INT8</strong></td>
                        <td>8-bit</td>
                        <td>~7GB</td>
                        <td>~98%</td>
                        <td>Server inference</td>
                    </tr>
                    <tr>
                        <td><strong>Q4_K_M</strong> ‚≠ê</td>
                        <td>4-bit</td>
                        <td class="table-highlight">~4GB</td>
                        <td class="table-highlight">~94%</td>
                        <td>Laptop/desktop, best balance</td>
                    </tr>
                    <tr>
                        <td><strong>Q3_K_M</strong></td>
                        <td>3-bit</td>
                        <td>~3GB</td>
                        <td>~90%</td>
                        <td>Memory-constrained devices</td>
                    </tr>
                    <tr>
                        <td><strong>Q2_K</strong></td>
                        <td>2-bit</td>
                        <td>~2GB</td>
                        <td>~85%</td>
                        <td>Extreme compression, testing</td>
                    </tr>
                </tbody>
            </table>

            <div class="deep-dive">
                <div class="deep-header">
                    <div class="deep-icon">‚≠ê</div>
                    <div>
                        <div class="deep-title">Q4 is the Sweet Spot</div>
                        <div class="deep-subtitle">Why 4-bit quantization dominates edge deployment</div>
                    </div>
                </div>
                <div class="deep-body">
                    <div class="deep-grid">
                        <div class="deep-section">
                            <h4>Why Q4 Works</h4>
                            <ul>
                                <li>8x size reduction vs FP32 with only ~6% quality loss</li>
                                <li>Makes 7B models run on 8GB RAM devices</li>
                                <li>K-quant methods (Q4_K_M, Q4_K_S) preserve important weights</li>
                                <li>Sweet spot between compression and perplexity</li>
                                <li>Widely supported by all inference runtimes</li>
                            </ul>
                        </div>
                        <div class="deep-section">
                            <h4>Quantization Methods</h4>
                            <ul>
                                <li><strong>GGUF/GGML:</strong> llama.cpp format, CPU-optimized, most common</li>
                                <li><strong>GPTQ:</strong> GPU-optimized, requires calibration data</li>
                                <li><strong>AWQ:</strong> Activation-aware, better quality at same bits</li>
                                <li><strong>ONNX:</strong> Cross-platform, DirectML support</li>
                                <li><strong>Core ML:</strong> Apple Neural Engine optimized</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Runtimes -->
        <section class="module" id="runtimes">
            <div class="module-header">
                <div class="module-icon">‚öôÔ∏è</div>
                <div class="module-info">
                    <h2>Inference Runtimes</h2>
                    <p>Software that runs models on devices</p>
                </div>
            </div>

            <table class="comparison-table">
                <thead>
                    <tr>
                        <th>Runtime</th>
                        <th>Platform</th>
                        <th>Format</th>
                        <th>Hardware</th>
                        <th>Best For</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>llama.cpp</strong></td>
                        <td>Cross-platform</td>
                        <td>GGUF</td>
                        <td>CPU, GPU (CUDA/Metal/Vulkan)</td>
                        <td>Most versatile, active development</td>
                    </tr>
                    <tr>
                        <td><strong>Ollama</strong></td>
                        <td>Mac, Linux, Windows</td>
                        <td>GGUF</td>
                        <td>CPU, GPU</td>
                        <td>Easy setup, model management</td>
                    </tr>
                    <tr>
                        <td><strong>MLX</strong></td>
                        <td>Apple Silicon</td>
                        <td>MLX, SafeTensors</td>
                        <td>Apple Neural Engine</td>
                        <td>Best Mac performance</td>
                    </tr>
                    <tr>
                        <td><strong>ONNX Runtime</strong></td>
                        <td>Cross-platform</td>
                        <td>ONNX</td>
                        <td>CPU, DirectML, CUDA</td>
                        <td>Windows, enterprise deployment</td>
                    </tr>
                    <tr>
                        <td><strong>Core ML</strong></td>
                        <td>Apple devices</td>
                        <td>mlmodel</td>
                        <td>Apple Neural Engine</td>
                        <td>iOS/macOS native apps</td>
                    </tr>
                    <tr>
                        <td><strong>TensorFlow Lite</strong></td>
                        <td>Mobile, embedded</td>
                        <td>TFLite</td>
                        <td>CPU, GPU delegates</td>
                        <td>Android, IoT devices</td>
                    </tr>
                </tbody>
            </table>

            <div class="overview-content">
                <div>
                    <h3>Consumer Applications</h3>
                    <ul>
                        <li><strong>LM Studio:</strong> Beautiful GUI, model hub browser, built-in API server. Best for beginners and testing models.</li>
                        <li><strong>Jan:</strong> Open source ChatGPT alternative. Clean interface, conversation management, plugin system.</li>
                        <li><strong>GPT4All:</strong> Privacy-focused, LocalDocs for RAG over your files. No telemetry.</li>
                        <li><strong>Open WebUI:</strong> Self-hosted Ollama frontend with multi-model support and chat history.</li>
                    </ul>
                </div>
                <div>
                    <h3>Developer Integration</h3>
                    <ul>
                        <li><strong>Ollama API:</strong> OpenAI-compatible REST API. Drop-in replacement for cloud providers.</li>
                        <li><strong>llama-cpp-python:</strong> Python bindings for llama.cpp. LangChain/LlamaIndex integration.</li>
                        <li><strong>AICore (Android):</strong> Google's on-device ML API. Access to Gemini Nano.</li>
                        <li><strong>Core ML Tools:</strong> Convert models to Core ML format for Apple deployment.</li>
                    </ul>
                </div>
            </div>
        </section>

        <!-- Privacy -->
        <section class="module" id="privacy">
            <div class="module-header">
                <div class="module-icon">üîê</div>
                <div class="module-info">
                    <h2>Privacy by Architecture</h2>
                    <p>Data that never leaves your device</p>
                </div>
            </div>

            <div class="overview-content" style="margin-bottom: 24px;">
                <div class="overview-full">
                    <h3>The Privacy Advantage</h3>
                    <p>Edge AI provides <strong>privacy by architecture</strong>, not just by policy. When AI runs locally, sensitive data physically cannot leave the device‚Äîthere's no server to send it to, no API to intercept, no database to breach. This isn't about trusting a privacy policy; it's about mathematical certainty that your data stays yours.</p>
                </div>
            </div>

            <div class="stats-row">
                <div class="stat-card">
                    <div class="stat-value">0</div>
                    <div class="stat-label">Data Transmitted</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">0</div>
                    <div class="stat-label">Server Logs Created</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">0</div>
                    <div class="stat-label">Third-Party Access</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">100%</div>
                    <div class="stat-label">User Control</div>
                </div>
            </div>

            <div class="deep-dive">
                <div class="deep-header">
                    <div class="deep-icon">üõ°Ô∏è</div>
                    <div>
                        <div class="deep-title">Compliance Simplified</div>
                        <div class="deep-subtitle">Regulatory benefits of edge AI</div>
                    </div>
                </div>
                <div class="deep-body">
                    <div class="deep-grid">
                        <div class="deep-section">
                            <h4>Healthcare (HIPAA)</h4>
                            <ul>
                                <li>PHI never transmitted‚Äîno BAA needed with AI vendor</li>
                                <li>On-device processing for clinical notes, diagnostics</li>
                                <li>Audit trail stays within hospital systems</li>
                                <li>Reduced attack surface for patient data</li>
                            </ul>
                        </div>
                        <div class="deep-section">
                            <h4>Finance & Legal</h4>
                            <ul>
                                <li>Client confidentiality maintained by default</li>
                                <li>No third-party data processing agreements</li>
                                <li>Meets data residency requirements automatically</li>
                                <li>Privileged information stays privileged</li>
                            </ul>
                        </div>
                        <div class="deep-section">
                            <h4>GDPR (EU)</h4>
                            <ul>
                                <li>No cross-border data transfers to manage</li>
                                <li>Data minimization built into architecture</li>
                                <li>Right to deletion is automatic (no server copy)</li>
                                <li>Simplified DPIA‚Äîno third-party processor risk</li>
                            </ul>
                        </div>
                        <div class="deep-section">
                            <h4>Enterprise Security</h4>
                            <ul>
                                <li>Air-gapped deployment possible</li>
                                <li>No API keys to secure or rotate</li>
                                <li>Works on classified/restricted networks</li>
                                <li>No cloud dependency for availability</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Use Cases -->
        <section class="module" id="usecases">
            <div class="module-header">
                <div class="module-icon">üíº</div>
                <div class="module-info">
                    <h2>Use Cases</h2>
                    <p>Where edge AI provides unique value</p>
                </div>
            </div>

            <div class="usecase-grid">
                <div class="usecase-card">
                    <div class="usecase-icon">üè•</div>
                    <div>
                        <div class="usecase-title">Healthcare</div>
                        <div class="usecase-desc">Process patient data locally for HIPAA compliance without cloud complexity. Real-time clinical decision support, medical device AI, wearable health monitoring with on-device anomaly detection.</div>
                        <div class="usecase-examples"><strong>Examples:</strong> Radiology assist, ECG analysis, clinical note summarization, drug interaction checking</div>
                    </div>
                </div>

                <div class="usecase-card">
                    <div class="usecase-icon">üöó</div>
                    <div>
                        <div class="usecase-title">Automotive</div>
                        <div class="usecase-desc">Real-time decisions at highway speeds‚Äîyou can't wait 500ms for cloud response at 70mph. ADAS, voice control, driver monitoring, predictive maintenance all require on-device processing.</div>
                        <div class="usecase-examples"><strong>Examples:</strong> Lane detection, voice commands, drowsiness detection, in-cabin monitoring</div>
                    </div>
                </div>

                <div class="usecase-card">
                    <div class="usecase-icon">üè≠</div>
                    <div>
                        <div class="usecase-title">Manufacturing</div>
                        <div class="usecase-desc">Air-gapped factory networks can't reach cloud. Real-time quality inspection at production line speeds. Predictive maintenance to prevent downtime. Edge AI enables Industry 4.0.</div>
                        <div class="usecase-examples"><strong>Examples:</strong> Visual defect detection, anomaly detection, robotics control, process optimization</div>
                    </div>
                </div>

                <div class="usecase-card">
                    <div class="usecase-icon">üì±</div>
                    <div>
                        <div class="usecase-title">Mobile Apps</div>
                        <div class="usecase-desc">Instant AI features without API costs at scale. Offline functionality for travel, rural areas, or spotty connectivity. No per-request pricing eating into margins.</div>
                        <div class="usecase-examples"><strong>Examples:</strong> Photo enhancement, smart keyboard, voice notes, document scanning</div>
                    </div>
                </div>

                <div class="usecase-card">
                    <div class="usecase-icon">üéÆ</div>
                    <div>
                        <div class="usecase-title">Gaming & AR/VR</div>
                        <div class="usecase-desc">Zero-latency AI for immersive experiences. AI NPCs that respond instantly. Real-time gesture and voice recognition. Adaptive difficulty and procedural content generation.</div>
                        <div class="usecase-examples"><strong>Examples:</strong> AI companions, voice commands, gesture control, real-time translation in multiplayer</div>
                    </div>
                </div>

                <div class="usecase-card">
                    <div class="usecase-icon">üè†</div>
                    <div>
                        <div class="usecase-title">Smart Home & IoT</div>
                        <div class="usecase-desc">Local voice assistants that work without internet. Privacy-preserving security cameras with on-device person detection. No cloud subscription fees for basic AI features.</div>
                        <div class="usecase-examples"><strong>Examples:</strong> Wake word detection, face recognition, activity monitoring, energy optimization</div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Best Practices -->
        <section class="module" id="practices">
            <div class="module-header">
                <div class="module-icon">‚úÖ</div>
                <div class="module-info">
                    <h2>Best Practices</h2>
                    <p>Guidelines for successful edge AI deployment</p>
                </div>
            </div>

            <div class="practices-grid">
                <div class="practice-card">
                    <div class="practice-num">1</div>
                    <div>
                        <div class="practice-title">Right-Size Your Model</div>
                        <div class="practice-desc">Don't use 7B when 1B suffices. Benchmark your specific task‚Äîsmaller models are faster, use less battery, and generate less heat. Start small, scale up only if quality insufficient.</div>
                    </div>
                </div>

                <div class="practice-card">
                    <div class="practice-num">2</div>
                    <div>
                        <div class="practice-title">Design for Hybrid</div>
                        <div class="practice-desc">Edge for simple/sensitive tasks, cloud for complex reasoning. Implement graceful fallback when offline. Apple's Private Cloud Compute shows how to do this well.</div>
                    </div>
                </div>

                <div class="practice-card">
                    <div class="practice-num">3</div>
                    <div>
                        <div class="practice-title">Test Quantization Levels</div>
                        <div class="practice-desc">Q4_K_M is usually optimal, but benchmark for your task. Code generation may need Q5+; classification often works at Q3. Always validate against your evaluation set.</div>
                    </div>
                </div>

                <div class="practice-card">
                    <div class="practice-num">4</div>
                    <div>
                        <div class="practice-title">Use Platform APIs First</div>
                        <div class="practice-desc">Apple Intelligence, Gemini Nano, and Windows AI are free, optimized, and maintained by platform vendors. Only bundle your own models if platform APIs don't meet your needs.</div>
                    </div>
                </div>

                <div class="practice-card">
                    <div class="practice-num">5</div>
                    <div>
                        <div class="practice-title">Monitor Thermal & Battery</div>
                        <div class="practice-desc">AI inference is compute-intensive. Implement request throttling, batch operations when possible, and respect device thermal state. Users won't tolerate hot phones with dead batteries.</div>
                    </div>
                </div>

                <div class="practice-card">
                    <div class="practice-num">6</div>
                    <div>
                        <div class="practice-title">Set User Expectations</div>
                        <div class="practice-desc">On-device AI isn't GPT-4. Communicate capabilities clearly‚Äîusers appreciate honest limitations over overpromising. "Smart suggestions" is better than "AI assistant" for small models.</div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Future -->
        <section class="module" id="future">
            <div class="module-header">
                <div class="module-icon">üîÆ</div>
                <div class="module-info">
                    <h2>The Future of Edge AI</h2>
                    <p>Where on-device AI is headed</p>
                </div>
            </div>

            <div class="timeline-container">
                <div class="timeline-row">
                    <div class="timeline-year">2024</div>
                    <div class="timeline-content"><strong>Platform AI launches:</strong> Apple Intelligence, Gemini Nano, Copilot+ PCs ship to consumers. NPUs become standard in flagship devices. 40+ TOPS becomes the baseline for "AI PCs."</div>
                </div>
                <div class="timeline-row">
                    <div class="timeline-year">2025</div>
                    <div class="timeline-content"><strong>NPU performance doubles:</strong> 100+ TOPS in laptops, better small models (Llama 4 small, Phi-4). On-device image generation becomes practical. Local RAG over personal documents.</div>
                </div>
                <div class="timeline-row">
                    <div class="timeline-year">2026</div>
                    <div class="timeline-content"><strong>Multimodal goes local:</strong> On-device vision-language models. Real-time video understanding. Local voice assistants rivaling cloud quality. Agents that work offline.</div>
                </div>
                <div class="timeline-row">
                    <div class="timeline-year">2027+</div>
                    <div class="timeline-content"><strong>Cloud-quality on-device:</strong> Model efficiency improvements make today's cloud quality tomorrow's edge quality. AI becomes a utility like WiFi‚Äîexpected everywhere, no connection required.</div>
                </div>
            </div>

            <div class="overview-content">
                <div class="overview-full">
                    <h3>The Trajectory is Clear</h3>
                    <p>Every year brings better NPUs, smaller high-quality models, and more efficient inference. What required a data center in 2020 runs on phones in 2025. The trend is unmistakable: <strong>most AI will eventually run locally</strong>, with cloud reserved for training and the most complex reasoning tasks. Privacy and latency win in the long run. Build for edge today; it's where AI is going.</p>
                </div>
            </div>
        </section>

        <!-- Agent This -->
        <section class="module" id="agent">
            <div class="module-header">
                <div class="module-icon">ü§ñ</div>
                <div class="module-info">
                    <h2>Agent This</h2>
                    <p>Edge deployment optimization agent</p>
                </div>
            </div>

            <div class="agent-grid">
                <div class="agent-info">
                    <h3>üì± EdgeDeployer</h3>
                    <p>An agent that helps optimize and deploy models for edge devices. It analyzes model requirements, recommends quantization strategies, generates deployment configurations, and benchmarks performance across device targets.</p>
                    <div class="agent-capabilities">
                        <div class="agent-capability"><span class="capability-icon">üìè</span> Analyze model size and memory requirements</div>
                        <div class="agent-capability"><span class="capability-icon">üéØ</span> Recommend target devices based on constraints</div>
                        <div class="agent-capability"><span class="capability-icon">üìâ</span> Select optimal quantization level</div>
                        <div class="agent-capability"><span class="capability-icon">‚öôÔ∏è</span> Generate runtime configuration files</div>
                        <div class="agent-capability"><span class="capability-icon">üìä</span> Benchmark inference performance</div>
                        <div class="agent-capability"><span class="capability-icon">üîã</span> Estimate battery/thermal impact</div>
                    </div>
                </div>
                <div class="agent-code">
                    <div class="code-header">edge_deployer.py</div>
                    <div class="code-content">
<pre><span class="ck">from</span> crewai <span class="ck">import</span> Agent, Task, Crew
<span class="ck">from</span> langchain_anthropic <span class="ck">import</span> ChatAnthropic

llm = ChatAnthropic(model=<span class="cs">"claude-sonnet-4-20250514"</span>)

edge_deployer = Agent(
    role=<span class="cs">"Edge AI Deployment Specialist"</span>,
    goal=<span class="cs">"Optimize models for edge devices"</span>,
    backstory=<span class="cs">"""Expert in model quantization, NPU 
    optimization, and mobile deployment. Deep knowledge
    of llama.cpp, ONNX, Core ML, and platform APIs."""</span>,
    tools=[
        ModelAnalyzer(),
        QuantizationTool(),
        BenchmarkRunner(),
        ConfigGenerator()
    ],
    llm=llm
)

<span class="ck">async def</span> <span class="cf">deploy_to_edge</span>(model_path, target_device, constraints):
    task = Task(
        description=<span class="cs">f"""Deploy {model_path} to {target_device}.
        Constraints: {constraints}
        Output: Quantized model + runtime config + benchmarks"""</span>,
        agent=edge_deployer,
        expected_output=<span class="cs">"Deployment package with benchmarks"</span>
    )
    crew = Crew(agents=[edge_deployer], tasks=[task])
    <span class="ck">return await</span> crew.kickoff_async()</pre>
                    </div>
                </div>
            </div>
        </section>

        <!-- Related -->
        <section class="module">
            <div class="module-header">
                <div class="module-icon">üìö</div>
                <div class="module-info">
                    <h2>Related Topics</h2>
                    <p>Continue exploring</p>
                </div>
            </div>
            <div class="related-grid">
                <a href="cat19-p1-foundation-models.html" class="related-card">
                    <div class="related-icon">üß†</div>
                    <div class="related-title">Foundation Models</div>
                    <div class="related-desc">The models being optimized for edge deployment</div>
                </a>
                <a href="cat19-p6-ai-infrastructure.html" class="related-card">
                    <div class="related-icon">üñ•Ô∏è</div>
                    <div class="related-title">AI Infrastructure</div>
                    <div class="related-desc">Cloud infrastructure for hybrid edge/cloud deployments</div>
                </a>
                <a href="cat19-p7-ai-safety.html" class="related-card">
                    <div class="related-icon">üõ°Ô∏è</div>
                    <div class="related-title">AI Safety & Governance</div>
                    <div class="related-desc">Privacy, security, and compliance considerations</div>
                </a>
            </div>
        </section>

    </div>
</div>

<footer>
    <div class="footer-nav">
        <a href="cat19-p4-ai-coding.html" class="footer-link">
            <span>‚Üê</span>
            <div>
                <div class="footer-link-label">Previous</div>
                <div class="footer-link-title">19.4 AI Coding Tools</div>
            </div>
        </a>
        <div class="footer-brand"><span>STRATEGY</span>HUB ‚Ä¢ Page 19.5</div>
        <a href="cat19-p6-ai-infrastructure.html" class="footer-link">
            <div>
                <div class="footer-link-label">Next</div>
                <div class="footer-link-title">19.6 AI Infrastructure</div>
            </div>
            <span>‚Üí</span>
        </a>
    </div>
</footer>

</body>
</html>
